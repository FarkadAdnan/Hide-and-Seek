# Hide-and-Seek
 Through multi-agent competition, the simple goal of hide-and-seek and standardized augmentative learning algorithms on a large scale, we find that agents create a self-supervised approach that catalyses multiple distinct rounds of emerging strategy, many of which require sophisticated use and coordination of the tool. We find clear evidence of six emerging stages in the agent's strategy in our environment, each of which creates new pressure on the opposing team to adapt; For example, Agents learn to build multi-purpose shelters using moving boxes which in turn lead to Agents discovering that they can overcome obstacles using ramps. We also provide evidence that multi-agent competition may better expand with increasing environmental complexity and lead to behavior focused on more human-relevant skills than self-supervised reinforcement learning methods such as intrinsic motivation. Finally, we propose transfer and tuning as a method to quantitatively assess target abilities, and compare hide-and-seek factors with both intrinsic motivation and random baselines on a set of domain-specific IQ tests
